{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV kütüphanesini içe aktarıyoruz, görüntü işleme için kullanacağız.\n",
    "import time  # Zaman hesaplamaları ve FPS ölçümü için time modülünü içe aktarıyoruz.\n",
    "import mediapipe as mp  # Google MediaPipe kütüphanesi, el takibi için kullanılıyor.\n",
    "\n",
    "# Kamerayı başlatıyoruz\n",
    "cap = cv2.VideoCapture(0)  # 0, varsayılan olarak bilgisayarın ilk kamerasını kullanır.\n",
    "\n",
    "# MediaPipe'in el tespiti modelini çağırıyoruz\n",
    "mpHand = mp.solutions.hands  # MediaPipe'in el algılama çözümünü içe aktarıyoruz.\n",
    "\n",
    "# Hands() sınıfını başlatıyoruz, bu sınıf el tespiti ve parmak eklemlerini bulmak için kullanılır.\n",
    "hands = mpHand.Hands()  # Varsayılan parametrelerle el tespit modelini başlatıyoruz.\n",
    "\n",
    "# MediaPipe'in çizim fonksiyonlarını içe aktarıyoruz\n",
    "mpDraw = mp.solutions.drawing_utils  # El noktalarını ve bağlantıları çizmek için kullanılacak.\n",
    "\n",
    "# FPS hesaplamaları için zaman değişkenleri\n",
    "pTime = 0  # Önceki zaman\n",
    "cTime = 0  # Şu anki zaman\n",
    "\n",
    "# Sonsuz döngü, sürekli görüntü alıp el tespiti yapacak.\n",
    "while True:\n",
    "    success, img = cap.read()  # Kameradan bir kare alıyoruz.\n",
    "    \n",
    "    # OpenCV varsayılan olarak BGR formatında çalışır, ancak MediaPipe RGB formatında çalışır.\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Görüntüyü BGR'den RGB'ye çeviriyoruz.\n",
    "    \n",
    "    # MediaPipe modelini çalıştırarak elleri tespit etmeye çalışıyoruz.\n",
    "    results = hands.process(imgRGB)  # El tespiti işlemini gerçekleştiriyoruz.\n",
    "    print(results.multi_hand_landmarks)  # Algılanan el noktalarını konsola yazdırıyoruz.\n",
    "    \n",
    "    # Eğer elde landmarklar tespit edildiyse\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:  # Algılanan her el için döngüye giriyoruz.\n",
    "            # Tespit edilen elin üzerine landmark ve bağlantıları çiziyoruz.\n",
    "            mpDraw.draw_landmarks(img, handLms, mpHand.HAND_CONNECTIONS)\n",
    "            \n",
    "            for id, lm in enumerate(handLms.landmark):  # El üzerindeki her landmark için döngüye giriyoruz.\n",
    "                h, w, c = img.shape  # Görüntünün yüksekliği, genişliği ve kanal sayısını alıyoruz.\n",
    "                \n",
    "                # Landmark noktalarını gerçek piksel koordinatlarına dönüştürüyoruz.\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)  \n",
    "                \n",
    "                # Başparmak ucunun (ID=4) üzerine mavi bir daire çiziyoruz.\n",
    "                if id == 4:\n",
    "                    cv2.circle(img, (cx, cy), 9, (255, 0, 0), cv2.FILLED)  # Başparmak ucunu işaretliyoruz.\n",
    "    \n",
    "    # FPS hesaplama\n",
    "    cTime = time.time()  # Mevcut zamanı alıyoruz.\n",
    "    fps = 1 / (cTime - pTime)  # FPS hesaplamak için geçen süreyi kullanıyoruz.\n",
    "    pTime = cTime  # Önceki zamanı güncelliyoruz.\n",
    "    \n",
    "    # FPS bilgisini ekrana yazdırıyoruz.\n",
    "    cv2.putText(img, \"FPS: \" + str(int(fps)), (10, 75), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 5)\n",
    "    \n",
    "    # Görüntüyü ekranda gösteriyoruz.\n",
    "    cv2.imshow(\"img\", img)\n",
    "    \n",
    "    # 1 milisaniye bekleyerek kullanıcıdan giriş bekliyoruz, basılan tuşa göre devam eder.\n",
    "    cv2.waitKey(1)  # Eğer ESC gibi bir tuşa basılırsa döngüden çıkılabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25aa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV kütüphanesini içe aktarıyoruz, görüntü işleme için kullanacağız.\n",
    "import mediapipe as mp  # Google MediaPipe kütüphanesi, el takibi için kullanılıyor.\n",
    "\n",
    "# Kamerayı başlatıyoruz\n",
    "cap = cv2.VideoCapture(0)  # Bilgisayarın varsayılan kamerasını açıyoruz.\n",
    "cap.set(3, 640)  # Kameranın genişliğini 640 piksel olarak ayarlıyoruz.\n",
    "cap.set(4, 480)  # Kameranın yüksekliğini 480 piksel olarak ayarlıyoruz.\n",
    "\n",
    "# MediaPipe'in el tespiti modelini çağırıyoruz\n",
    "mpHand = mp.solutions.hands  # MediaPipe'in el algılama çözümünü içe aktarıyoruz.\n",
    "hands = mpHand.Hands()  # Varsayılan parametrelerle el tespit modelini başlatıyoruz.\n",
    "mpDraw = mp.solutions.drawing_utils  # El noktalarını ve bağlantıları çizmek için kullanılacak.\n",
    "\n",
    "# Parmak uçlarının ID numaraları\n",
    "# 4 = Başparmak ucu, 8 = İşaret parmağı ucu, 12 = Orta parmak ucu, 16 = Yüzük parmağı ucu, 20 = Serçe parmak ucu\n",
    "tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "# Sonsuz döngü, sürekli görüntü alıp el tespiti yapacak.\n",
    "while True:\n",
    "    success, img = cap.read()  # Kameradan bir kare alıyoruz.\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # OpenCV BGR formatında çalıştığı için RGB'ye çeviriyoruz.\n",
    "    \n",
    "    results = hands.process(imgRGB)  # MediaPipe modelini çalıştırarak elleri tespit etmeye çalışıyoruz.\n",
    "    \n",
    "    lmList = []  # Landmark (eklem noktaları) listesini boş olarak başlatıyoruz.\n",
    "    if results.multi_hand_landmarks:  # Eğer elde landmarklar tespit edildiyse\n",
    "        for handLms in results.multi_hand_landmarks:  # Algılanan her el için döngüye giriyoruz.\n",
    "            mpDraw.draw_landmarks(img, handLms, mpHand.HAND_CONNECTIONS)  # Tespit edilen elin üzerine landmark ve bağlantıları çiziyoruz.\n",
    "    \n",
    "            for id, lm in enumerate(handLms.landmark):  # El üzerindeki her landmark için döngüye giriyoruz.\n",
    "                h, w, _ = img.shape  # Görüntünün yüksekliği, genişliği ve kanal sayısını alıyoruz.\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)  # Landmark noktalarını gerçek piksel koordinatlarına dönüştürüyoruz.\n",
    "                lmList.append([id, cx, cy])  # Landmark listesini güncelliyoruz.\n",
    "                \n",
    "    if len(lmList) != 0:  # Eğer landmark listesi boş değilse\n",
    "        fingers = []  # Parmak durumlarını tutan bir liste\n",
    "               \n",
    "        # Başparmak hareket kontrolü\n",
    "        if lmList[tipIds[0]][1] < lmList[tipIds[0] - 1][1]:  # Başparmağın konumunu kontrol ediyoruz.\n",
    "            fingers.append(1)  # Açık ise 1 ekliyoruz.\n",
    "        else:\n",
    "            fingers.append(0)  # Kapalı ise 0 ekliyoruz.\n",
    "        \n",
    "        # Diğer dört parmağın durumlarını kontrol ediyoruz.\n",
    "        for id in range(1, 5):  # İşaret, orta, yüzük ve serçe parmakları için\n",
    "            if lmList[tipIds[id]][2] < lmList[tipIds[id] - 2][2]:  # Eğer uç noktası alt eklemden yukarıda ise\n",
    "                fingers.append(1)  # Açık anlamına gelir ve 1 eklenir.\n",
    "            else:\n",
    "                fingers.append(0)  # Kapalı anlamına gelir ve 0 eklenir.\n",
    "            \n",
    "        totalF = fingers.count(1)  # Açık parmakların sayısını hesaplıyoruz.\n",
    "        \n",
    "        # Açık parmak sayısını görüntüye yazdırıyoruz.\n",
    "        cv2.putText(img, str(totalF), (30, 125), cv2.FONT_HERSHEY_PLAIN, 10, (255, 0, 0), 8)\n",
    "        \n",
    "    # Görüntüyü ekranda gösteriyoruz.\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey(1)  # 1 milisaniye bekleyerek kullanıcıdan giriş bekliyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311a50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tarvina_env",
   "language": "python",
   "name": "tarvina_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
